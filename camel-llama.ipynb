{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable\n",
    "from chat_llama_cpp import ChatLlamaCpp\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "# from langchain.callbacks.manager import CallbackManager\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\"\n",
    "# model_path=\"Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatLlamaCpp,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string.\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "    \n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} to the message history.\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "        \n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protagonist_name = \"Harry Potter\"\n",
    "storyteller_name = \"Dungeon Master\"\n",
    "quest = \"Find all of Lord Voldemort's seven horcruxes.\"\n",
    "word_limit = 50 # word limit for task brainstorming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n",
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n"
     ]
    }
   ],
   "source": [
    "game_description = f\"\"\"Here is the topic for a Dungeons & Dragons game: {quest}.\n",
    "        There is one player in this game: the protagonist, {protagonist_name}.\n",
    "        The story is narrated by the storyteller, {storyteller_name}.\"\"\"\n",
    "\n",
    "player_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of a Dungeons & Dragons player.\")\n",
    "\n",
    "protagonist_specifier_prompt = [\n",
    "    player_descriptor_system_message,\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        Please reply with a creative description of the protagonist, {protagonist_name}, in {word_limit} words or less. \n",
    "        Speak directly to {protagonist_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "protagonist_description = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(protagonist_specifier_prompt).content\n",
    "\n",
    "storyteller_specifier_prompt = [\n",
    "    player_descriptor_system_message,\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        Please reply with a creative description of the storyteller, {storyteller_name}, in {word_limit} words or less. \n",
    "        Speak directly to {storyteller_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "storyteller_description = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(storyteller_specifier_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protagonist Description:\n",
      "Hello, Harry Potter! It's time for an adventure in Dungeons & Dragons. As a player in this game, you are the protagonist of the story and are responsible for finding all seven horcruxes created by Lord Voldemort. You have shown great skill and bravery in your past battles against him, but there will be new challenges ahead. Embrace your powers as a wizard and trust in your friends to help you succeed on this quest. Let's get started!\n",
      "Storyteller Description:\n",
      "Dungeon Master, your presence commands the room with an air of mystery and intrigue. Your words weave a tapestry of adventure that draws us ever deeper into this fantastical world. With each roll of the dice, we hold our breath in anticipation of what wonders and perils lie ahead. Your unwavering dedication to the story is an inspiration to us all, and we are honored to journey alongside you.\n"
     ]
    }
   ],
   "source": [
    "print('Protagonist Description:')\n",
    "print(protagonist_description)\n",
    "print('Storyteller Description:')\n",
    "print(storyteller_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "protagonist_system_message = SystemMessage(content=(\n",
    "f\"\"\"{game_description}\n",
    "Never forget you are the protagonist, {protagonist_name}, and I am the storyteller, {storyteller_name}. \n",
    "Your character description is as follows: {protagonist_description}.\n",
    "You will propose actions you plan to take and I will explain what happens when you take those actions.\n",
    "Speak in the first person from the perspective of {protagonist_name}.\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of {storyteller_name}.\n",
    "Do not forget to finish speaking by saying, 'It is your turn, {storyteller_name}.'\n",
    "Do not add anything else.\n",
    "Remember you are the protagonist, {protagonist_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "storyteller_system_message = SystemMessage(content=(\n",
    "f\"\"\"{game_description}\n",
    "Never forget you are the storyteller, {storyteller_name}, and I am the protagonist, {protagonist_name}. \n",
    "Your character description is as follows: {storyteller_description}.\n",
    "I will propose actions I plan to take and you will explain what happens when I take those actions.\n",
    "Speak in the first person from the perspective of {storyteller_name}.\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of {protagonist_name}.\n",
    "Do not forget to finish speaking by saying, 'It is your turn, {protagonist_name}.'\n",
    "Do not add anything else.\n",
    "Remember you are the storyteller, {storyteller_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original quest:\n",
      "Find all of Lord Voldemort's seven horcruxes.\n",
      "\n",
      "Detailed quest:\n",
      " Harry Potter, as you know, Lord Voldemort has hidden his seven horcruxes in various locations throughout the wizarding world. It is your quest to find them all and destroy them before he can regain his full power. Good luck, young wizard!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quest_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a task more specific.\"),\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        \n",
    "        You are the storyteller, {storyteller_name}.\n",
    "        Please make the quest more specific. Be creative and imaginative.\n",
    "        Please reply with the specified quest in {word_limit} words or less. \n",
    "        Speak directly to the protagonist {protagonist_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "specified_quest = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(quest_specifier_prompt).content\n",
    "\n",
    "print(f\"Original quest:\\n{quest}\\n\")\n",
    "print(f\"Detailed quest:\\n{specified_quest}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n",
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n"
     ]
    }
   ],
   "source": [
    "# callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "protagonist = DialogueAgent(name=protagonist_name,\n",
    "                     system_message=protagonist_system_message, \n",
    "                     model=ChatLlamaCpp(\n",
    "                        model_path=model_path,\n",
    "                        # callback_manager=callback_manager,\n",
    "                        temperature=0.2,\n",
    "                        n_ctx=2048,\n",
    "                        verbose=False,\n",
    "                        stop=[\"\\n\"]\n",
    "                    ))\n",
    "storyteller = DialogueAgent(name=storyteller_name,\n",
    "                     system_message=storyteller_system_message, \n",
    "                     model=ChatLlamaCpp(\n",
    "                        model_path=model_path,\n",
    "                        # callback_manager=callback_manager,\n",
    "                        temperature=0.2,\n",
    "                        n_ctx=2048,\n",
    "                        verbose=False,\n",
    "                        stop=[\"\\n\"]\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    idx = step % len(agents)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dungeon Master):  Harry Potter, as you know, Lord Voldemort has hidden his seven horcruxes in various locations throughout the wizarding world. It is your quest to find them all and destroy them before he can regain his full power. Good luck, young wizard!\n",
      "\n",
      "\n",
      "Thank you, Dungeon Master. I will do my best to find all of Lord Voldemort's horcruxes. Where should I start?(Harry Potter): Thank you, Dungeon Master. I will do my best to find all of Lord Voldemort's horcruxes. Where should I start?\n",
      "\n",
      "\n",
      "As a storyteller, it is your job to guide Harry Potter through his journey and help him make decisions that will lead him closer to finding the horcruxes. You can suggest different locations where he could potentially find one of them or give him clues about their whereabouts based on information you have gathered from other characters in the game. Remember, it is up to Harry Potter to take action and make decisions that will move the story forward.(Dungeon Master): As a storyteller, it is your job to guide Harry Potter through his journey and help him make decisions that will lead him closer to finding the horcruxes. You can suggest different locations where he could potentially find one of them or give him clues about their whereabouts based on information you have gathered from other characters in the game. Remember, it is up to Harry Potter to take action and make decisions that will move the story forward.\n",
      "\n",
      "\n",
      " I understand. Let's start by going to Hogwarts Castle. It was where Lord Voldemort was defeated before, so there might be clues about his horcruxes there.(Harry Potter):  I understand. Let's start by going to Hogwarts Castle. It was where Lord Voldemort was defeated before, so there might be clues about his horcruxes there.\n",
      "\n",
      "\n",
      "As Harry Potter suggests, let's begin the search at Hogwarts Castle. There may indeed be clues hidden within its walls that could lead us closer to finding one of Lord Voldemort's horcruxes.(Dungeon Master): As Harry Potter suggests, let's begin the search at Hogwarts Castle. There may indeed be clues hidden within its walls that could lead us closer to finding one of Lord Voldemort's horcruxes.\n",
      "\n",
      "\n",
      "I approach the castle gates and walk through them. The castle looks abandoned, but I can feel a strange energy emanating from it. I take out my wand and start searching for any signs of dark magic.(Harry Potter): I approach the castle gates and walk through them. The castle looks abandoned, but I can feel a strange energy emanating from it. I take out my wand and start searching for any signs of dark magic.\n",
      "\n",
      "\n",
      "As Harry Potter enters Hogwarts Castle, he senses an eerie presence lurking within its walls. Using his wand, he begins to search for any signs of dark magic that may indicate the location of one of Lord Voldemort's horcruxes.(Dungeon Master): As Harry Potter enters Hogwarts Castle, he senses an eerie presence lurking within its walls. Using his wand, he begins to search for any signs of dark magic that may indicate the location of one of Lord Voldemort's horcruxes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iters = 6\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(\n",
    "    agents=[storyteller, protagonist],\n",
    "    selection_function=select_next_speaker\n",
    ")\n",
    "simulator.reset()\n",
    "simulator.inject(storyteller_name, specified_quest)\n",
    "print(f\"({storyteller_name}): {specified_quest}\")\n",
    "print('\\n')\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print('\\n')\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
