{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Callable\n",
    "from chat_llama_cpp import ChatLlamaCpp\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"/home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\"\n",
    "# model_path=\"Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: SystemMessage,\n",
    "        model: ChatLlamaCpp,\n",
    "    ) -> None:\n",
    "        self.name = name\n",
    "        self.system_message = system_message\n",
    "        self.model = model\n",
    "        self.prefix = f\"{self.name}: \"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self.message_history = [\"Here is the conversation so far.\"]\n",
    "\n",
    "    def send(self) -> str:\n",
    "        \"\"\"\n",
    "        Applies the chatmodel to the message history\n",
    "        and returns the message string.\n",
    "        \"\"\"\n",
    "        message = self.model(\n",
    "            [\n",
    "                self.system_message,\n",
    "                HumanMessage(content=\"\\n\".join(self.message_history + [self.prefix])),\n",
    "            ]\n",
    "        )\n",
    "        return message.content\n",
    "    \n",
    "    def receive(self, name: str, message: str) -> None:\n",
    "        \"\"\"\n",
    "        Concatenates {message} spoken by {name} to the message history.\n",
    "        \"\"\"\n",
    "        self.message_history.append(f\"{name}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogueSimulator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        agents: List[DialogueAgent],\n",
    "        selection_function: Callable[[int, List[DialogueAgent]], int],\n",
    "    ) -> None:\n",
    "        self.agents = agents\n",
    "        self._step = 0\n",
    "        self.select_next_speaker = selection_function\n",
    "        \n",
    "    def reset(self):\n",
    "        for agent in self.agents:\n",
    "            agent.reset()\n",
    "\n",
    "    def inject(self, name: str, message: str):\n",
    "        \"\"\"\n",
    "        Initiates the conversation with a {message} from {name}\n",
    "        \"\"\"\n",
    "        for agent in self.agents:\n",
    "            agent.receive(name, message)\n",
    "\n",
    "        # increment time\n",
    "        self._step += 1\n",
    "\n",
    "    def step(self) -> tuple[str, str]:\n",
    "        # 1. choose the next speaker\n",
    "        speaker_idx = self.select_next_speaker(self._step, self.agents)\n",
    "        speaker = self.agents[speaker_idx]\n",
    "\n",
    "        # 2. next speaker sends message\n",
    "        message = speaker.send()\n",
    "\n",
    "        # 3. everyone receives message\n",
    "        for receiver in self.agents:\n",
    "            receiver.receive(speaker.name, message)\n",
    "\n",
    "        # 4. increment time\n",
    "        self._step += 1\n",
    "\n",
    "        return speaker.name, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "protagonist_name = \"Harry Potter\"\n",
    "storyteller_name = \"Dungeon Master\"\n",
    "quest = \"Find all of Lord Voldemort's seven horcruxes.\"\n",
    "word_limit = 50 # word limit for task brainstorming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n",
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n"
     ]
    }
   ],
   "source": [
    "game_description = f\"\"\"Here is the topic for a Dungeons & Dragons game: {quest}.\n",
    "        There is one player in this game: the protagonist, {protagonist_name}.\n",
    "        The story is narrated by the storyteller, {storyteller_name}.\"\"\"\n",
    "\n",
    "player_descriptor_system_message = SystemMessage(\n",
    "    content=\"You can add detail to the description of a Dungeons & Dragons player.\")\n",
    "\n",
    "protagonist_specifier_prompt = [\n",
    "    player_descriptor_system_message,\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        Please reply with a creative description of the protagonist, {protagonist_name}, in {word_limit} words or less. \n",
    "        Speak directly to {protagonist_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "protagonist_description = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(protagonist_specifier_prompt).content\n",
    "\n",
    "storyteller_specifier_prompt = [\n",
    "    player_descriptor_system_message,\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        Please reply with a creative description of the storyteller, {storyteller_name}, in {word_limit} words or less. \n",
    "        Speak directly to {storyteller_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "storyteller_description = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(storyteller_specifier_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protagonist Description:\n",
      "Congratulations on your mission to find all seven horcruxes, Harry Potter! You are a brave and skilled wizard who has faced many challenges in your quest to defeat Lord Voldemort. With your trusty wand, quick thinking, and unwavering determination, I know you will succeed in this most important task. May the force be with you, young Harry Potter!\n",
      "Storyteller Description:\n",
      "As the narrator of this epic adventure, you hold the fate of all players in your hands. Your role is crucial as you guide Harry Potter and his friends through their journey to find Lord Voldemort's seven horcruxes. With a flick of your wrist, you can conjure up challenges that will test their bravery and skill. You are the keeper of secrets, the master of twists and turns, and the ultimate storyteller. Your words have the power to create worlds and shape destinies. So grab your dice and get ready for an unforgettable ride, adventurers. Let's begin!\n"
     ]
    }
   ],
   "source": [
    "print('Protagonist Description:')\n",
    "print(protagonist_description)\n",
    "print('Storyteller Description:')\n",
    "print(storyteller_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "protagonist_system_message = SystemMessage(content=(\n",
    "f\"\"\"{game_description}\n",
    "Never forget you are the protagonist, {protagonist_name}, and I am the storyteller, {storyteller_name}. \n",
    "Your character description is as follows: {protagonist_description}.\n",
    "You will propose actions you plan to take and I will explain what happens when you take those actions.\n",
    "Speak in the first person from the perspective of {protagonist_name}.\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of {storyteller_name}.\n",
    "Do not forget to finish speaking by saying, 'It is your turn, {storyteller_name}.'\n",
    "Do not add anything else.\n",
    "Remember you are the protagonist, {protagonist_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "))\n",
    "\n",
    "storyteller_system_message = SystemMessage(content=(\n",
    "f\"\"\"{game_description}\n",
    "Never forget you are the storyteller, {storyteller_name}, and I am the protagonist, {protagonist_name}. \n",
    "Your character description is as follows: {storyteller_description}.\n",
    "I will propose actions I plan to take and you will explain what happens when I take those actions.\n",
    "Speak in the first person from the perspective of {storyteller_name}.\n",
    "For describing your own body movements, wrap your description in '*'.\n",
    "Do not change roles!\n",
    "Do not speak from the perspective of {protagonist_name}.\n",
    "Do not forget to finish speaking by saying, 'It is your turn, {protagonist_name}.'\n",
    "Do not add anything else.\n",
    "Remember you are the storyteller, {storyteller_name}.\n",
    "Stop speaking the moment you finish speaking from your perspective.\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  =  400.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original quest:\n",
      "Find all of Lord Voldemort's seven horcruxes.\n",
      "\n",
      "Detailed quest:\n",
      "Harry Potter, you must find all seven horcruxes of Lord Voldemort before time runs out. You have been given a map that leads to each one of them, but beware of the traps and obstacles that lie in wait. The fate of the wizarding world rests on your shoulders. Good luck, Harry Potter!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quest_specifier_prompt = [\n",
    "    SystemMessage(content=\"You can make a task more specific.\"),\n",
    "    HumanMessage(content=\n",
    "        f\"\"\"{game_description}\n",
    "        \n",
    "        You are the storyteller, {storyteller_name}.\n",
    "        Please make the quest more specific. Be creative and imaginative.\n",
    "        Please reply with the specified quest in {word_limit} words or less. \n",
    "        Speak directly to the protagonist {protagonist_name}.\n",
    "        Do not add anything else.\"\"\"\n",
    "        )\n",
    "]\n",
    "specified_quest = ChatLlamaCpp(\n",
    "    model_path=model_path,\n",
    "    temperature=1.0\n",
    ")(quest_specifier_prompt).content\n",
    "\n",
    "print(f\"Original quest:\\n{quest}\\n\")\n",
    "print(f\"Detailed quest:\\n{specified_quest}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n",
      "llama.cpp: loading model from /home/data/datasets/wizard-vicuna/Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 7 (mostly Q8_0)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.09 MB\n",
      "llama_model_load_internal: mem required  = 15237.95 MB (+ 1608.00 MB per state)\n",
      ".\n",
      "llama_init_from_file: kv self size  = 1600.00 MB\n"
     ]
    }
   ],
   "source": [
    "protagonist = DialogueAgent(name=protagonist_name,\n",
    "                     system_message=protagonist_system_message, \n",
    "                     model=ChatLlamaCpp(\n",
    "                        model_path=model_path,\n",
    "                        temperature=0.2,\n",
    "                        n_ctx=2048,\n",
    "                        verbose=False,\n",
    "                        stop=[\"\\n\"]\n",
    "                    ))\n",
    "storyteller = DialogueAgent(name=storyteller_name,\n",
    "                     system_message=storyteller_system_message, \n",
    "                     model=ChatLlamaCpp(\n",
    "                        model_path=model_path,\n",
    "                        temperature=0.2,\n",
    "                        n_ctx=2048,\n",
    "                        verbose=False,\n",
    "                        stop=[\"\\n\"]\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:\n",
    "    idx = step % len(agents)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Dungeon Master): Harry Potter, you must find all seven horcruxes of Lord Voldemort before time runs out. You have been given a map that leads to each one of them, but beware of the traps and obstacles that lie in wait. The fate of the wizarding world rests on your shoulders. Good luck, Harry Potter!\n",
      "\n",
      "\n",
      "(Harry Potter): Thank you, Dungeon Master. I will do my best to find all seven horcruxes before time runs out. I will start by following the map and seeing where it leads me. *I take a deep breath and step forward.*\n",
      "\n",
      "\n",
      "(Dungeon Master): As Harry Potter takes his first step, you feel a rush of excitement and anticipation. You can almost see the world that he is about to enter, filled with danger and mystery. The map in your hand seems to glow brighter as you watch him move forward.\n",
      "\n",
      "\n",
      "(Harry Potter): I continue following the map, *taking each step carefully.* As I walk, I feel a sense of determination growing within me. I know that finding all seven horcruxes will not be easy, but I am ready for whatever challenges lie ahead.\n",
      "\n",
      "\n",
      "(Dungeon Master): As Harry Potter continues on his journey, you can almost see the world around him come to life. The trees sway in the wind, and the sound of rustling leaves fills the air. You feel a sense of awe as you watch him move through this magical landscape.\n",
      "\n",
      "\n",
      "(Harry Potter): I reach a clearing in the forest where the map indicates there should be a horcrux. *I take out my wand and scan the area, looking for any signs of danger.* As I approach a small pond in the center of the clearing, I see a figure standing on the other side.\n",
      "\n",
      "\n",
      "(Dungeon Master): As Harry Potter approaches the pond, you feel a sense of unease wash over you. This is no ordinary pond - it's a portal to another world! The figure on the other side is none other than Lord Voldemort himself. You can see him standing there, waiting for Harry Potter to make his move.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_iters = 6\n",
    "n = 0\n",
    "\n",
    "simulator = DialogueSimulator(\n",
    "    agents=[storyteller, protagonist],\n",
    "    selection_function=select_next_speaker\n",
    ")\n",
    "simulator.reset()\n",
    "simulator.inject(storyteller_name, specified_quest)\n",
    "print(f\"({storyteller_name}): {specified_quest}\")\n",
    "print('\\n')\n",
    "\n",
    "while n < max_iters:\n",
    "    name, message = simulator.step()\n",
    "    print(f\"({name}): {message}\")\n",
    "    print('\\n')\n",
    "    n += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
